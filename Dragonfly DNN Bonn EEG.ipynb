{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2164,"status":"ok","timestamp":1763869503744,"user":{"displayName":"Ibrahim Al-Akash","userId":"03956035445069945231"},"user_tz":360},"id":"ZaOTJw8xc5T-","outputId":"4de15e6d-0a59-462b-c16d-01aef005ad20"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/Shareddrives/AI Health Project/Project Code\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# ðŸ‘‡ change this to the folder that contains your `Data/` directory\n","%cd \"/content/drive/Shareddrives/AI Health Project/Project Code\""]},{"cell_type":"markdown","metadata":{"id":"9aea4c66"},"source":["# Task\n","Load the 'A', 'D', and 'E' EEG datasets from the directory '/content/drive/Shareddrives/AI Health Project/Project Code/BONN EEG Dataset'. For each of these datasets, read all the individual text files (e.g., 'Z001.txt' to 'Z100.txt' for 'A') and concatenate them to form complete EEG signals for each category."]},{"cell_type":"markdown","metadata":{"id":"82cdfec9"},"source":["## Load BONN EEG Data\n","\n","### Subtask:\n","Load the 'A', 'D', and 'E' EEG datasets from the specified path, read all individual text files for each dataset, and concatenate them to form complete EEG signals for each category.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L2KWSmP_ygXm","executionInfo":{"status":"ok","timestamp":1763869523297,"user_tz":360,"elapsed":4226,"user":{"displayName":"Ibrahim Al-Akash","userId":"03956035445069945231"}},"outputId":"64cc8bd8-ff87-43f3-a0db-6e9ff7fba279"},"outputs":[{"output_type":"stream","name":"stdout","text":["EEG data loaded and concatenated.\n","Categories loaded: ['A', 'D', 'E']\n","Labels created: ['A', 'D', 'E']\n","Shape of 'A' dataset: (409700,)\n"]}],"source":["import os\n","import numpy as np\n","\n","dataset_prefixes = ['A','D','E']\n","bonn_eeg_dir = '/content/drive/Shareddrives/AI Health Project/Project Code/BONN EEG Dataset'\n","\n","# Initialize an empty dictionary to store the concatenated EEG signals for each category\n","eeg_data_dict = {}\n","# Initialize an empty list to store the corresponding category labels\n","labels = []\n","\n","# Iterate through each prefix in the dataset_prefixes list\n","for prefix in dataset_prefixes:\n","    # Construct the full path to the directory containing the text files for the current prefix\n","    prefix_dir = os.path.join(bonn_eeg_dir, prefix)\n","\n","    # Initialize an empty list to temporarily store the EEG data for the current prefix\n","    current_prefix_signals = []\n","\n","    # Get a list of all files in the current prefix's directory and filter for .txt files\n","    try:\n","        all_files = os.listdir(prefix_dir)\n","        text_files = sorted([f for f in all_files if f.endswith('.txt')])\n","    except FileNotFoundError:\n","        print(f\"Directory not found: {prefix_dir}. Skipping prefix {prefix}.\")\n","        continue\n","\n","    # For each sorted text file, load the data and append to current_prefix_signals\n","    for file_name in text_files:\n","        file_path = os.path.join(prefix_dir, file_name)\n","        data = np.loadtxt(file_path)\n","        current_prefix_signals.append(data)\n","\n","    # Concatenate all arrays in current_prefix_signals into a single NumPy array\n","    if current_prefix_signals:\n","        concatenated_signal = np.concatenate(current_prefix_signals)\n","        # Store this concatenated array in the eeg_data_dict with the prefix as the key\n","        eeg_data_dict[prefix] = concatenated_signal\n","        # Append the prefix to the labels list\n","        labels.append(prefix)\n","    else:\n","        print(f\"No .txt files found in {prefix_dir}. Skipping prefix {prefix}.\")\n","\n","print(\"EEG data loaded and concatenated.\")\n","print(f\"Categories loaded: {list(eeg_data_dict.keys())}\")\n","print(f\"Labels created: {labels}\")\n","\n","# Display the shape of one of the loaded datasets as an example\n","if 'A' in eeg_data_dict:\n","    print(f\"Shape of 'A' dataset: {eeg_data_dict['A'].shape}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"obcfOqcdynIA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763869534805,"user_tz":360,"elapsed":2011,"user":{"displayName":"Ibrahim Al-Akash","userId":"03956035445069945231"}},"outputId":"5581df99-00de-4507-e114-b797540f33e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total samples loaded: 300\n","Shape of first sample: (4097,)\n","Labels distribution: (array(['A', 'D', 'E'], dtype='<U1'), array([100, 100, 100]))\n"]}],"source":["import os\n","import numpy as np\n","\n","# 1. Initialize empty lists\n","X_raw = []\n","y_raw = []\n","\n","# 2. Define base directory path\n","base_dir = '/content/drive/Shareddrives/AI Health Project/Project Code/BONN EEG Dataset'\n","categories = ['A', 'D', 'E']\n","\n","# 3. Iterate through categories\n","for category in categories:\n","    folder_path = os.path.join(base_dir, category)\n","\n","    # 4. List and sort .txt files\n","    try:\n","        file_names = sorted([f for f in os.listdir(folder_path) if f.endswith('.txt')])\n","    except FileNotFoundError:\n","        print(f\"Directory not found: {folder_path}\")\n","        continue\n","\n","    # 5. Loop through files and load data\n","    for file_name in file_names:\n","        file_path = os.path.join(folder_path, file_name)\n","        try:\n","            data = np.loadtxt(file_path)\n","            X_raw.append(data)\n","            y_raw.append(category)\n","        except Exception as e:\n","            print(f\"Error loading {file_path}: {e}\")\n","\n","# 6. Verify loaded data\n","print(f\"Total samples loaded: {len(X_raw)}\")\n","if len(X_raw) > 0:\n","    print(f\"Shape of first sample: {X_raw[0].shape}\")\n","    print(f\"Labels distribution: {np.unique(y_raw, return_counts=True)}\")"]},{"cell_type":"markdown","metadata":{"id":"b1f5ebc5"},"source":["## Preprocessing and Trimming\n","\n","### Subtask:\n","Preprocess the 300 raw EEG segments by trimming them to 4096 data points, applying a 40Hz low-pass filter, and normalizing the values to the range [-1, 1].\n"]},{"cell_type":"markdown","metadata":{"id":"8e61a5aa"},"source":["**Reasoning**:\n","The user wants to preprocess the raw EEG data by trimming, filtering, and normalizing each of the 300 segments individually. I will implement the specified signal processing steps: designing a Butterworth low-pass filter, iterating through the raw data list, applying the filter and normalization to each trimmed segment, and storing the results in a new array.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1124,"status":"ok","timestamp":1763869537853,"user":{"displayName":"Ibrahim Al-Akash","userId":"03956035445069945231"},"user_tz":360},"id":"862ed230","outputId":"efc30997-cbd8-4643-a77a-39fe53cbfc85"},"outputs":[{"output_type":"stream","name":"stdout","text":["Preprocessing complete.\n","Shape of X_processed: (300, 4096)\n"]}],"source":["from scipy.signal import butter, filtfilt\n","import numpy as np\n","\n","# 1. Define parameters\n","sfreq = 173.61\n","cutoff_freq = 40.0\n","nyquist = sfreq / 2\n","order = 5\n","\n","# 2. Design Butterworth low-pass filter\n","b, a = butter(order, cutoff_freq / nyquist, btype='low')\n","\n","# 3. Initialize list for processed signals\n","X_processed = []\n","\n","# 4. Iterate, trim, filter, and normalize\n","for signal in X_raw:\n","    # Trim to 4096 points\n","    trimmed_signal = signal[:4096]\n","\n","    # Apply low-pass filter\n","    filtered_signal = filtfilt(b, a, trimmed_signal)\n","\n","    # Normalize to [-1, 1]\n","    max_abs_val = np.max(np.abs(filtered_signal))\n","    if max_abs_val > 0:\n","        normalized_signal = filtered_signal / max_abs_val\n","    else:\n","        normalized_signal = filtered_signal\n","\n","    X_processed.append(normalized_signal)\n","\n","# 5. Convert to numpy array\n","X_processed = np.array(X_processed)\n","\n","print(f\"Preprocessing complete.\")\n","print(f\"Shape of X_processed: {X_processed.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"cd5bbd5d"},"source":["## SWT Decomposition (Level 4)\n","\n","### Subtask:\n","Apply Stationary Wavelet Transform (SWT) using the 'db4' wavelet at level 4 to each of the 300 preprocessed EEG signals.\n"]},{"cell_type":"markdown","metadata":{"id":"3d02592a"},"source":["**Reasoning**:\n","Perform Stationary Wavelet Transform (SWT) on the preprocessed EEG signals. Since the signal length is 4096, a 4-level decomposition is feasible (4096 is divisible by 2^4=16). I will iterate through the `X_processed` array, apply `pywt.swt` with 'db4' wavelet at level 4, and store the coefficients.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":590,"status":"ok","timestamp":1763869540388,"user":{"displayName":"Ibrahim Al-Akash","userId":"03956035445069945231"},"user_tz":360},"id":"8aa3b08b","outputId":"6dccd3b7-5934-48a6-c519-7140038fdc75"},"outputs":[{"output_type":"stream","name":"stdout","text":["SWT Decomposition complete.\n","Number of decomposed samples: 300\n","Decomposition levels per sample: 4\n","Level 4: cA shape=(4096,), cD shape=(4096,)\n","Level 3: cA shape=(4096,), cD shape=(4096,)\n","Level 2: cA shape=(4096,), cD shape=(4096,)\n","Level 1: cA shape=(4096,), cD shape=(4096,)\n"]}],"source":["import pywt\n","\n","# 1. Define wavelet parameters\n","wavelet = 'db4'\n","level = 4\n","\n","# 2. Initialize list for decomposed signals\n","X_decomposed = []\n","\n","# 3. Iterate through processed signals and apply SWT\n","for signal in X_processed:\n","    # Apply Stationary Wavelet Transform\n","    # signal length is 4096, which is a multiple of 2^4 (16), so level 4 is valid.\n","    coeffs = pywt.swt(signal, wavelet, level=level)\n","    X_decomposed.append(coeffs)\n","\n","print(\"SWT Decomposition complete.\")\n","if len(X_decomposed) > 0:\n","    print(f\"Number of decomposed samples: {len(X_decomposed)}\")\n","    print(f\"Decomposition levels per sample: {len(X_decomposed[0])}\")\n","    # coeffs is a list of tuples (approximation, detail)\n","    # Let's verify the shape of coefficients at the last level (level 4)\n","    # coeffs[0] corresponds to level 1 if swt returns [level1, level2...] or vice versa?\n","    # pywt.swt returns coefficients starting from the highest decomposition level (approximation, detail)\n","    # effectively [(cA_n, cD_n), ..., (cA_1, cD_1)]\n","\n","    # Checking the structure\n","    for i, (cA, cD) in enumerate(X_decomposed[0]):\n","        print(f\"Level {level-i}: cA shape={cA.shape}, cD shape={cD.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"39dbe7ff"},"source":["## Feature Extraction\n","\n","### Subtask:\n","Extract statistical features and Hjorth parameters from all SWT coefficients and calculate ratios between adjacent detail coefficients for each EEG segment.\n"]},{"cell_type":"markdown","metadata":{"id":"7bf2c290"},"source":["**Reasoning**:\n","I will define a function to calculate statistical features and Hjorth parameters for each signal coefficient. Then, I will iterate through the decomposed signals, extracting these features for all levels (A and D) and computing the specified ratios between detail coefficients. Finally, I will aggregate all features into a pandas DataFrame.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7789,"status":"ok","timestamp":1763869551018,"user":{"displayName":"Ibrahim Al-Akash","userId":"03956035445069945231"},"user_tz":360},"id":"dfd60462","outputId":"fed417b3-e806-4a1a-b1a3-054ccb111b24"},"outputs":[{"output_type":"stream","name":"stdout","text":["Feature extraction complete.\n","Shape of features_df: (300, 67)\n","   A4_mean_abs    A4_std   A4_skew  A4_kurtosis    A4_rms  A4_activity  \\\n","0     0.514273  0.630681 -0.312607     0.580392  0.646412     0.397759   \n","1     0.839970  0.480984 -0.200557     0.159825  0.957043     0.231345   \n","2     0.629943  0.735013  0.046509     0.012972  0.783670     0.540244   \n","3     0.488936  0.606446  0.045974     0.337587  0.613040     0.367777   \n","4     0.637755  0.665370  0.289895    -0.305466  0.765576     0.442717   \n","\n","   A4_mobility  A4_complexity  D4_mean_abs    D4_std  ...    D1_std   D1_skew  \\\n","0     0.096125       1.805612     0.350261  0.442862  ...  0.013104  0.002062   \n","1     0.099726       1.992681     0.308872  0.394569  ...  0.013773  0.498374   \n","2     0.085663       1.925613     0.348887  0.449802  ...  0.014312 -0.099478   \n","3     0.105121       1.929247     0.415642  0.532707  ...  0.027106 -0.001890   \n","4     0.077112       2.335658     0.330770  0.428103  ...  0.015439  0.003122   \n","\n","   D1_kurtosis    D1_rms  D1_activity  D1_mobility  D1_complexity  \\\n","0     0.396569  0.013104     0.000172     0.969827       1.062908   \n","1     8.074100  0.013773     0.000190     1.021585       1.155741   \n","2     1.355264  0.014312     0.000205     0.995234       1.120223   \n","3     0.332221  0.027106     0.000735     1.011478       1.067779   \n","4     0.018304  0.015439     0.000238     1.012486       1.063775   \n","\n","   ratio_D1_D2  ratio_D2_D3  ratio_D3_D4  \n","0     0.144737     0.325127     0.631797  \n","1     0.142875     0.335181     0.720691  \n","2     0.142999     0.294329     0.772754  \n","3     0.160198     0.433929     0.744294  \n","4     0.154676     0.312883     0.765585  \n","\n","[5 rows x 67 columns]\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from scipy.stats import skew, kurtosis\n","\n","def calculate_features(signal):\n","    \"\"\"Calculates statistical and Hjorth features for a given signal.\"\"\"\n","    mav = np.mean(np.abs(signal))\n","    std = np.std(signal)\n","    skw = skew(signal)\n","    kurt = kurtosis(signal)\n","    rms = np.sqrt(np.mean(signal**2))\n","\n","    # Hjorth Parameters\n","    activity = np.var(signal)\n","    gradient = np.diff(signal)\n","    mobility = np.sqrt(np.var(gradient) / activity) if activity > 0 else 0\n","\n","    grad_mobility = np.sqrt(np.var(np.diff(gradient)) / np.var(gradient)) if np.var(gradient) > 0 else 0\n","    complexity = grad_mobility / mobility if mobility > 0 else 0\n","\n","    return {\n","        'mean_abs': mav,\n","        'std': std,\n","        'skew': skw,\n","        'kurtosis': kurt,\n","        'rms': rms,\n","        'activity': activity,\n","        'mobility': mobility,\n","        'complexity': complexity\n","    }\n","\n","features_list = []\n","\n","# Iterate through each decomposed sample\n","for idx, coeffs in enumerate(X_decomposed):\n","    # coeffs structure from pywt.swt with level=4 is [(cA4, cD4), (cA3, cD3), (cA2, cD2), (cA1, cD1)]\n","    # We map them to names for easier access\n","\n","    # Level 4\n","    A4, D4 = coeffs[0]\n","    # Level 3\n","    A3, D3 = coeffs[1]\n","    # Level 2\n","    A2, D2 = coeffs[2]\n","    # Level 1\n","    A1, D1 = coeffs[3]\n","\n","    coeff_map = {\n","        'A4': A4, 'D4': D4,\n","        'A3': A3, 'D3': D3,\n","        'A2': A2, 'D2': D2,\n","        'A1': A1, 'D1': D1\n","    }\n","\n","    sample_features = {}\n","\n","    # Extract features for each coefficient\n","    for name, signal in coeff_map.items():\n","        feats = calculate_features(signal)\n","        for key, val in feats.items():\n","            sample_features[f\"{name}_{key}\"] = val\n","\n","    # Calculate ratios of MAV for adjacent detail coefficients\n","    # Ratios: D1/D2, D2/D3, D3/D4\n","    d1_mav = sample_features['D1_mean_abs']\n","    d2_mav = sample_features['D2_mean_abs']\n","    d3_mav = sample_features['D3_mean_abs']\n","    d4_mav = sample_features['D4_mean_abs']\n","\n","    sample_features['ratio_D1_D2'] = d1_mav / d2_mav if d2_mav != 0 else 0\n","    sample_features['ratio_D2_D3'] = d2_mav / d3_mav if d3_mav != 0 else 0\n","    sample_features['ratio_D3_D4'] = d3_mav / d4_mav if d4_mav != 0 else 0\n","\n","    features_list.append(sample_features)\n","\n","# Create DataFrame\n","features_df = pd.DataFrame(features_list)\n","\n","print(f\"Feature extraction complete.\")\n","print(f\"Shape of features_df: {features_df.shape}\")\n","print(features_df.head())"]},{"cell_type":"markdown","metadata":{"id":"d223d35d"},"source":["**Reasoning**:\n","Before performing feature selection using the Binary Dragonfly Algorithm, the categorical labels need to be encoded into numerical values, and the features should be standardized to ensure optimal performance of the distance-based classifier (likely KNN) used within the wrapper method.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79,"status":"ok","timestamp":1763869553353,"user":{"displayName":"Ibrahim Al-Akash","userId":"03956035445069945231"},"user_tz":360},"id":"b9987a74","outputId":"44434e68-c0d2-4c08-a777-8a3022535b56"},"outputs":[{"output_type":"stream","name":"stdout","text":["Labels encoded and features scaled.\n","Classes: ['A' 'D' 'E']\n","Shape of X_scaled: (300, 67)\n"]}],"source":["from sklearn.preprocessing import LabelEncoder, StandardScaler\n","\n","# Encode labels\n","le = LabelEncoder()\n","y = le.fit_transform(y_raw)\n","\n","# Scale features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(features_df)\n","\n","print(\"Labels encoded and features scaled.\")\n","print(f\"Classes: {le.classes_}\")\n","print(f\"Shape of X_scaled: {X_scaled.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"6bdce98d"},"source":["**Reasoning**:\n","I will implement the Binary Dragonfly Algorithm (BDFA) to select the optimal subset of features from the processed dataset. This involves defining a `BDFA` class that optimizes a binary feature mask by maximizing the cross-validated accuracy of a K-Nearest Neighbors classifier (the fitness function). Finally, I will run the algorithm to identify the most relevant features and create a new dataset `X_selected` containing only those features.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2546,"status":"ok","timestamp":1763869557971,"user":{"displayName":"Ibrahim Al-Akash","userId":"03956035445069945231"},"user_tz":360},"id":"d679e0fa","outputId":"67c39493-3d8d-4a40-9d06-eab5aef9b775"},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting BDFA Feature Selection...\n","Iteration 5/20, Best Fitness: 0.9467, Num Features: 39\n","Iteration 10/20, Best Fitness: 0.9467, Num Features: 39\n","Iteration 15/20, Best Fitness: 0.9467, Num Features: 39\n","Iteration 20/20, Best Fitness: 0.9500, Num Features: 56\n","\n","Optimization Complete.\n","Best Accuracy (KNN Wrapper): 0.9500\n","Selected Features (56): ['A4_mean_abs', 'A4_std', 'A4_kurtosis', 'A4_rms', 'A4_complexity', 'D4_mean_abs', 'D4_std', 'D4_skew', 'D4_kurtosis', 'D4_rms', 'D4_activity', 'D4_mobility', 'D4_complexity', 'A3_mean_abs', 'A3_std', 'A3_skew', 'A3_kurtosis', 'A3_rms', 'A3_activity', 'A3_mobility', 'A3_complexity', 'D3_mean_abs', 'D3_std', 'D3_skew', 'D3_kurtosis', 'D3_activity', 'D3_mobility', 'D3_complexity', 'A2_std', 'A2_skew', 'A2_kurtosis', 'A2_rms', 'A2_mobility', 'A2_complexity', 'D2_mean_abs', 'D2_std', 'D2_kurtosis', 'D2_rms', 'D2_activity', 'D2_mobility', 'A1_mean_abs', 'A1_skew', 'A1_kurtosis', 'A1_rms', 'A1_activity', 'A1_mobility', 'A1_complexity', 'D1_mean_abs', 'D1_std', 'D1_skew', 'D1_kurtosis', 'D1_rms', 'D1_mobility', 'D1_complexity', 'ratio_D2_D3', 'ratio_D3_D4']\n","Shape of X_selected: (300, 56)\n"]}],"source":["import numpy as np\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import cross_val_score\n","\n","class BDFA:\n","    def __init__(self, n_agents, max_iter, n_features, X, y):\n","        self.n_agents = n_agents\n","        self.max_iter = max_iter\n","        self.n_features = n_features\n","        self.X = X\n","        self.y = y\n","        self.positions = np.random.randint(2, size=(n_agents, n_features))\n","        self.steps = np.zeros((n_agents, n_features))\n","        self.fitness = np.full(n_agents, -np.inf)\n","        self.food_pos = np.zeros(n_features)\n","        self.food_fitness = -np.inf\n","        self.enemy_pos = np.zeros(n_features)\n","        self.enemy_fitness = np.inf\n","\n","    def get_fitness(self, mask):\n","        if np.sum(mask) == 0:\n","            return -np.inf\n","        # Use a simple KNN for wrapper evaluation\n","        clf = KNeighborsClassifier(n_neighbors=5)\n","        X_sub = self.X[:, mask.astype(bool)]\n","        # 3-fold CV for speed and generalization\n","        scores = cross_val_score(clf, X_sub, self.y, cv=3, scoring='accuracy')\n","        return scores.mean()\n","\n","    def step(self, t):\n","        # Update inertia weight (w) and other parameters\n","        w = 0.9 - t * ((0.9 - 0.4) / self.max_iter)\n","\n","        # Weights for separation, alignment, cohesion, food, enemy\n","        # Using simplified global interaction model for efficiency\n","        f_w = 1.0; e_w = 1.0\n","\n","        # Evaluate fitness\n","        for i in range(self.n_agents):\n","            fit = self.get_fitness(self.positions[i])\n","            self.fitness[i] = fit\n","\n","            # Update Food (Best Solution)\n","            if fit > self.food_fitness:\n","                self.food_fitness = fit\n","                self.food_pos = self.positions[i].copy()\n","\n","            # Update Enemy (Worst Solution)\n","            if fit < self.enemy_fitness:\n","                self.enemy_fitness = fit\n","                self.enemy_pos = self.positions[i].copy()\n","\n","        # Update agents\n","        for i in range(self.n_agents):\n","            # Attraction to Food and Distraction from Enemy\n","            F = self.food_pos - self.positions[i]\n","            E = self.enemy_pos + self.positions[i]\n","\n","            # Update step vector (simulating velocity)\n","            self.steps[i] = (f_w * F + e_w * E) + w * self.steps[i]\n","\n","            # Sigmoid Transfer Function for Binarization\n","            sigmoid = 1 / (1 + np.exp(-self.steps[i]))\n","\n","            # Update position based on probability\n","            r = np.random.rand(self.n_features)\n","            self.positions[i] = (r < sigmoid).astype(int)\n","\n","    def run(self):\n","        for t in range(self.max_iter):\n","            self.step(t)\n","            if (t+1) % 5 == 0:\n","                print(f\"Iteration {t+1}/{self.max_iter}, Best Fitness: {self.food_fitness:.4f}, Num Features: {np.sum(self.food_pos)}\")\n","\n","        return self.food_pos, self.food_fitness\n","\n","# Run BDFA\n","# Using 10 agents and 20 iterations for demonstration speed\n","print(\"Starting BDFA Feature Selection...\")\n","bdfa = BDFA(n_agents=10, max_iter=20, n_features=X_scaled.shape[1], X=X_scaled, y=y)\n","best_mask_binary, best_score = bdfa.run()\n","\n","# Apply selection\n","best_mask = best_mask_binary.astype(bool)\n","\n","# If no features selected (edge case), select all or a fallback\n","if np.sum(best_mask) == 0:\n","    print(\"Warning: No features selected. Reverting to all features.\")\n","    best_mask = np.ones(X_scaled.shape[1], dtype=bool)\n","\n","selected_feature_names = features_df.columns[best_mask]\n","X_selected = X_scaled[:, best_mask]\n","\n","print(f\"\\nOptimization Complete.\")\n","print(f\"Best Accuracy (KNN Wrapper): {best_score:.4f}\")\n","print(f\"Selected Features ({sum(best_mask)}): {list(selected_feature_names)}\")\n","print(f\"Shape of X_selected: {X_selected.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"a1ad8a5a"},"source":["## Feature Selection (BDFA)\n","\n","### Subtask:\n","Encode labels, standardize features, and perform feature selection using the Binary Dragonfly Algorithm (BDFA).\n"]},{"cell_type":"markdown","metadata":{"id":"9b2d6693"},"source":["**Reasoning**:\n","I will start by importing the necessary libraries, encoding the categorical labels into numerical values, and standardizing the features. This prepares the data for the feature selection process.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1763869564236,"user":{"displayName":"Ibrahim Al-Akash","userId":"03956035445069945231"},"user_tz":360},"id":"965d147b","outputId":"52a14e97-3d8c-43f2-e25e-c781451b7c92"},"outputs":[{"output_type":"stream","name":"stdout","text":["Classes: ['A' 'D' 'E']\n","Shape of X_scaled: (300, 67)\n"]}],"source":["from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import cross_val_score\n","import numpy as np\n","\n","# Encode labels\n","le = LabelEncoder()\n","y = le.fit_transform(y_raw)\n","print(f\"Classes: {le.classes_}\")\n","\n","# Scale features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(features_df)\n","print(f\"Shape of X_scaled: {X_scaled.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2337,"status":"ok","timestamp":1763869568688,"user":{"displayName":"Ibrahim Al-Akash","userId":"03956035445069945231"},"user_tz":360},"id":"c7ae4f26","outputId":"2ec53d41-42fb-4870-802a-51262adfaa57"},"outputs":[{"output_type":"stream","name":"stdout","text":["Classes: ['A' 'D' 'E']\n","Shape of X_scaled: (300, 67)\n","Starting BDFA optimization...\n","Iteration 5/20, Best Fitness: 0.9400, Features: 59\n","Iteration 10/20, Best Fitness: 0.9400, Features: 59\n","Iteration 15/20, Best Fitness: 0.9433, Features: 62\n","Iteration 20/20, Best Fitness: 0.9433, Features: 62\n","\n","Optimization Results:\n","Best Accuracy: 0.9433\n","Selected 62 features.\n","Feature names: ['A4_mean_abs', 'A4_std', 'A4_skew', 'A4_kurtosis', 'A4_rms', 'A4_activity', 'A4_mobility', 'A4_complexity', 'D4_mean_abs', 'D4_std', 'D4_skew', 'D4_kurtosis', 'D4_rms', 'D4_activity', 'D4_mobility', 'D4_complexity', 'A3_mean_abs', 'A3_std', 'A3_skew', 'A3_kurtosis', 'A3_rms', 'A3_activity', 'A3_mobility', 'A3_complexity', 'D3_mean_abs', 'D3_std', 'D3_kurtosis', 'D3_rms', 'D3_activity', 'D3_mobility', 'D3_complexity', 'A2_mean_abs', 'A2_std', 'A2_skew', 'A2_kurtosis', 'A2_rms', 'A2_activity', 'A2_mobility', 'A2_complexity', 'D2_mean_abs', 'D2_std', 'D2_rms', 'D2_activity', 'D2_mobility', 'D2_complexity', 'A1_std', 'A1_kurtosis', 'A1_rms', 'A1_activity', 'A1_mobility', 'A1_complexity', 'D1_mean_abs', 'D1_std', 'D1_skew', 'D1_kurtosis', 'D1_rms', 'D1_activity', 'D1_mobility', 'D1_complexity', 'ratio_D1_D2', 'ratio_D2_D3', 'ratio_D3_D4']\n","Shape of X_selected: (300, 62)\n"]}],"source":["from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import cross_val_score\n","import numpy as np\n","\n","# 1-3. Encode labels and Standardize features (ensure variables are ready)\n","# Re-running to ensure environment consistency with new imports\n","le = LabelEncoder()\n","y = le.fit_transform(y_raw)\n","print(f\"Classes: {le.classes_}\")\n","\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(features_df)\n","print(f\"Shape of X_scaled: {X_scaled.shape}\")\n","\n","# 4. Define BDFA Class\n","class BDFA:\n","    def __init__(self, n_agents, max_iter, n_features, X, y):\n","        self.n_agents = n_agents\n","        self.max_iter = max_iter\n","        self.n_features = n_features\n","        self.X = X\n","        self.y = y\n","\n","        # Initialize random binary positions\n","        self.positions = np.random.randint(2, size=(n_agents, n_features))\n","        # Initialize step vectors\n","        self.steps = np.zeros((n_agents, n_features))\n","        # Fitness array\n","        self.fitness = np.full(n_agents, -np.inf)\n","\n","        # Food (Best solution found)\n","        self.food_pos = np.zeros(n_features)\n","        self.food_fitness = -np.inf\n","\n","        # Enemy (Worst solution found)\n","        self.enemy_pos = np.zeros(n_features)\n","        self.enemy_fitness = np.inf\n","\n","    def get_fitness(self, mask):\n","        # If no features selected, fitness is lowest possible\n","        if np.sum(mask) == 0:\n","            return -np.inf\n","\n","        # Select features\n","        X_subset = self.X[:, mask.astype(bool)]\n","\n","        # Evaluate using KNN with 3-fold CV\n","        clf = KNeighborsClassifier(n_neighbors=5)\n","        scores = cross_val_score(clf, X_subset, self.y, cv=3, scoring='accuracy')\n","        return scores.mean()\n","\n","    def step(self, t):\n","        # Update inertia weight\n","        w = 0.9 - t * ((0.9 - 0.4) / self.max_iter)\n","\n","        # Standard Dragonfly weights\n","        s_w = 0.1  # Separation\n","        a_w = 0.1  # Alignment\n","        c_w = 0.1  # Cohesion\n","        f_w = 1.0  # Food attraction\n","        e_w = 1.0  # Enemy distraction\n","\n","        # Evaluate fitness for all agents\n","        for i in range(self.n_agents):\n","            fit = self.get_fitness(self.positions[i])\n","            self.fitness[i] = fit\n","\n","            # Update Food (Best)\n","            if fit > self.food_fitness:\n","                self.food_fitness = fit\n","                self.food_pos = self.positions[i].copy()\n","\n","            # Update Enemy (Worst)\n","            if fit < self.enemy_fitness:\n","                self.enemy_fitness = fit\n","                self.enemy_pos = self.positions[i].copy()\n","\n","        # Calculate swarm global metrics for simplified calculation\n","        total_pos = np.sum(self.positions, axis=0)\n","        total_step = np.sum(self.steps, axis=0)\n","\n","        for i in range(self.n_agents):\n","            # Neighbors metrics (Global swarm)\n","            sum_pos_others = total_pos - self.positions[i]\n","            sum_step_others = total_step - self.steps[i]\n","            N_others = self.n_agents - 1\n","            if N_others == 0: N_others = 1\n","\n","            # Separation (S)\n","            S = - (N_others * self.positions[i] - sum_pos_others)\n","            # Alignment (A)\n","            A = sum_step_others / N_others\n","            # Cohesion (C)\n","            C = (sum_pos_others / N_others) - self.positions[i]\n","            # Food (F)\n","            F = self.food_pos - self.positions[i]\n","            # Enemy (E)\n","            E = self.enemy_pos + self.positions[i]\n","\n","            # Update Step Vector (Delta X)\n","            dX = (s_w * S + a_w * A + c_w * C + f_w * F + e_w * E) + w * self.steps[i]\n","\n","            # Clip dX to prevent overflow in sigmoid\n","            dX = np.clip(dX, -10, 10)\n","            self.steps[i] = dX\n","\n","            # Sigmoid Transfer Function for Binarization\n","            T = 1 / (1 + np.exp(-dX))\n","\n","            # Update Position\n","            r = np.random.rand(self.n_features)\n","            self.positions[i] = (r < T).astype(int)\n","\n","    def run(self):\n","        print(\"Starting BDFA optimization...\")\n","        for t in range(self.max_iter):\n","            self.step(t)\n","            if (t+1) % 5 == 0:\n","                print(f\"Iteration {t+1}/{self.max_iter}, Best Fitness: {self.food_fitness:.4f}, Features: {int(np.sum(self.food_pos))}\")\n","        return self.food_pos, self.food_fitness\n","\n","# 5-6. Instantiate and Run BDFA\n","bdfa = BDFA(n_agents=10, max_iter=20, n_features=X_scaled.shape[1], X=X_scaled, y=y)\n","best_mask_binary, best_score = bdfa.run()\n","\n","# 7. Apply Selection\n","best_mask = best_mask_binary.astype(bool)\n","\n","# Safety check if no features selected\n","if np.sum(best_mask) == 0:\n","    print(\"Warning: No features selected by BDFA. Reverting to all features.\")\n","    best_mask[:] = True\n","\n","X_selected = X_scaled[:, best_mask]\n","selected_feature_names = features_df.columns[best_mask].tolist()\n","\n","# 8. Print Results\n","print(\"\\nOptimization Results:\")\n","print(f\"Best Accuracy: {best_score:.4f}\")\n","print(f\"Selected {len(selected_feature_names)} features.\")\n","print(f\"Feature names: {selected_feature_names}\")\n","print(f\"Shape of X_selected: {X_selected.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DmWyN5URyxl6","outputId":"de73951d-6c20-462c-ad86-bef87cf23d0b","executionInfo":{"status":"ok","timestamp":1763869834895,"user_tz":360,"elapsed":18923,"user":{"displayName":"Ibrahim Al-Akash","userId":"03956035445069945231"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Training shape: (240, 62), Test shape: (60, 62)\n","Epoch 1/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.3449 - loss: 1.6237 - val_accuracy: 0.4583 - val_loss: 0.9344 - learning_rate: 0.0010\n","Epoch 2/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4778 - loss: 1.1889 - val_accuracy: 0.8333 - val_loss: 0.6733 - learning_rate: 0.0010\n","Epoch 3/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6606 - loss: 0.8889 - val_accuracy: 1.0000 - val_loss: 0.5353 - learning_rate: 0.0010\n","Epoch 4/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7091 - loss: 0.6699 - val_accuracy: 0.9583 - val_loss: 0.4334 - learning_rate: 0.0010\n","Epoch 5/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7393 - loss: 0.5789 - val_accuracy: 0.9583 - val_loss: 0.3680 - learning_rate: 0.0010\n","Epoch 6/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6835 - loss: 0.7293 - val_accuracy: 0.9583 - val_loss: 0.3311 - learning_rate: 0.0010\n","Epoch 7/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8280 - loss: 0.4353 - val_accuracy: 0.9583 - val_loss: 0.2933 - learning_rate: 0.0010\n","Epoch 8/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7814 - loss: 0.5509 - val_accuracy: 0.9583 - val_loss: 0.2602 - learning_rate: 0.0010\n","Epoch 9/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8638 - loss: 0.4422 - val_accuracy: 0.9583 - val_loss: 0.2421 - learning_rate: 0.0010\n","Epoch 10/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8119 - loss: 0.4493 - val_accuracy: 0.9583 - val_loss: 0.2281 - learning_rate: 0.0010\n","Epoch 11/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9096 - loss: 0.3298 - val_accuracy: 0.9583 - val_loss: 0.2139 - learning_rate: 0.0010\n","Epoch 12/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8694 - loss: 0.3124 - val_accuracy: 0.9583 - val_loss: 0.1986 - learning_rate: 0.0010\n","Epoch 13/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8989 - loss: 0.3368 - val_accuracy: 0.9583 - val_loss: 0.1778 - learning_rate: 0.0010\n","Epoch 14/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9140 - loss: 0.2973 - val_accuracy: 0.9583 - val_loss: 0.1618 - learning_rate: 0.0010\n","Epoch 15/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8783 - loss: 0.3270 - val_accuracy: 0.9583 - val_loss: 0.1513 - learning_rate: 0.0010\n","Epoch 16/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8690 - loss: 0.3415 - val_accuracy: 0.9583 - val_loss: 0.1478 - learning_rate: 0.0010\n","Epoch 17/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9067 - loss: 0.2759 - val_accuracy: 0.9583 - val_loss: 0.1363 - learning_rate: 0.0010\n","Epoch 18/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8989 - loss: 0.2841 - val_accuracy: 0.9583 - val_loss: 0.1274 - learning_rate: 0.0010\n","Epoch 19/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9444 - loss: 0.2739 - val_accuracy: 0.9583 - val_loss: 0.1206 - learning_rate: 0.0010\n","Epoch 20/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9292 - loss: 0.2272 - val_accuracy: 0.9583 - val_loss: 0.1150 - learning_rate: 0.0010\n","Epoch 21/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8887 - loss: 0.2461 - val_accuracy: 0.9583 - val_loss: 0.1030 - learning_rate: 0.0010\n","Epoch 22/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8933 - loss: 0.3028 - val_accuracy: 1.0000 - val_loss: 0.0924 - learning_rate: 0.0010\n","Epoch 23/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8996 - loss: 0.3373 - val_accuracy: 1.0000 - val_loss: 0.0868 - learning_rate: 0.0010\n","Epoch 24/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9374 - loss: 0.2105 - val_accuracy: 1.0000 - val_loss: 0.0752 - learning_rate: 0.0010\n","Epoch 25/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9275 - loss: 0.1967 - val_accuracy: 1.0000 - val_loss: 0.0715 - learning_rate: 0.0010\n","Epoch 26/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9547 - loss: 0.1785 - val_accuracy: 1.0000 - val_loss: 0.0729 - learning_rate: 0.0010\n","Epoch 27/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8888 - loss: 0.2229 - val_accuracy: 1.0000 - val_loss: 0.0683 - learning_rate: 0.0010\n","Epoch 28/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9483 - loss: 0.1400 - val_accuracy: 0.9583 - val_loss: 0.0776 - learning_rate: 0.0010\n","Epoch 29/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9678 - loss: 0.1423 - val_accuracy: 0.9583 - val_loss: 0.0858 - learning_rate: 0.0010\n","Epoch 30/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9312 - loss: 0.1612 - val_accuracy: 0.9583 - val_loss: 0.0751 - learning_rate: 0.0010\n","Epoch 31/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9672 - loss: 0.1445 - val_accuracy: 0.9583 - val_loss: 0.0740 - learning_rate: 0.0010\n","Epoch 32/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9336 - loss: 0.2416 - val_accuracy: 0.9583 - val_loss: 0.0851 - learning_rate: 0.0010\n","Epoch 33/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9294 - loss: 0.1652 - val_accuracy: 0.9583 - val_loss: 0.0852 - learning_rate: 0.0010\n","Epoch 34/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9569 - loss: 0.1262 - val_accuracy: 0.9583 - val_loss: 0.0827 - learning_rate: 0.0010\n","Epoch 35/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9371 - loss: 0.2097 - val_accuracy: 0.9583 - val_loss: 0.0712 - learning_rate: 0.0010\n","Epoch 36/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9651 - loss: 0.1211 - val_accuracy: 0.9583 - val_loss: 0.0719 - learning_rate: 0.0010\n","Epoch 37/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9464 - loss: 0.1598 - val_accuracy: 0.9583 - val_loss: 0.0662 - learning_rate: 0.0010\n","Epoch 38/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9406 - loss: 0.1436 - val_accuracy: 0.9583 - val_loss: 0.0692 - learning_rate: 0.0010\n","Epoch 39/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9333 - loss: 0.1532 - val_accuracy: 1.0000 - val_loss: 0.0639 - learning_rate: 0.0010\n","Epoch 40/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9861 - loss: 0.0929 - val_accuracy: 1.0000 - val_loss: 0.0596 - learning_rate: 0.0010\n","Epoch 41/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9250 - loss: 0.2137 - val_accuracy: 1.0000 - val_loss: 0.0583 - learning_rate: 0.0010\n","Epoch 42/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9617 - loss: 0.1359 - val_accuracy: 1.0000 - val_loss: 0.0619 - learning_rate: 0.0010\n","Epoch 43/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9527 - loss: 0.1438 - val_accuracy: 1.0000 - val_loss: 0.0562 - learning_rate: 0.0010\n","Epoch 44/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9651 - loss: 0.1209 - val_accuracy: 1.0000 - val_loss: 0.0626 - learning_rate: 0.0010\n","Epoch 45/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9741 - loss: 0.1010 - val_accuracy: 1.0000 - val_loss: 0.0705 - learning_rate: 0.0010\n","Epoch 46/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9637 - loss: 0.1093 - val_accuracy: 1.0000 - val_loss: 0.0602 - learning_rate: 0.0010\n","Epoch 47/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9644 - loss: 0.1405 - val_accuracy: 0.9583 - val_loss: 0.0740 - learning_rate: 0.0010\n","Epoch 48/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9857 - loss: 0.0725 - val_accuracy: 0.9583 - val_loss: 0.0837 - learning_rate: 0.0010\n","Epoch 49/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9747 - loss: 0.0808 - val_accuracy: 0.9583 - val_loss: 0.0697 - learning_rate: 0.0010\n","Epoch 50/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9302 - loss: 0.2052 - val_accuracy: 0.9583 - val_loss: 0.0628 - learning_rate: 0.0010\n","Epoch 51/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9791 - loss: 0.0732 - val_accuracy: 0.9583 - val_loss: 0.0606 - learning_rate: 0.0010\n","Epoch 52/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9658 - loss: 0.1223 - val_accuracy: 0.9583 - val_loss: 0.0586 - learning_rate: 0.0010\n","Epoch 53/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9701 - loss: 0.1055 - val_accuracy: 1.0000 - val_loss: 0.0468 - learning_rate: 0.0010\n","Epoch 54/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9623 - loss: 0.1089 - val_accuracy: 1.0000 - val_loss: 0.0385 - learning_rate: 0.0010\n","Epoch 55/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9112 - loss: 0.2138 - val_accuracy: 1.0000 - val_loss: 0.0471 - learning_rate: 0.0010\n","Epoch 56/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9704 - loss: 0.0930 - val_accuracy: 1.0000 - val_loss: 0.0444 - learning_rate: 0.0010\n","Epoch 57/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9675 - loss: 0.0924 - val_accuracy: 1.0000 - val_loss: 0.0464 - learning_rate: 0.0010\n","Epoch 58/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9760 - loss: 0.0871 - val_accuracy: 1.0000 - val_loss: 0.0409 - learning_rate: 0.0010\n","Epoch 59/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0625 - val_accuracy: 1.0000 - val_loss: 0.0341 - learning_rate: 0.0010\n","Epoch 60/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9702 - loss: 0.1010 - val_accuracy: 1.0000 - val_loss: 0.0276 - learning_rate: 0.0010\n","Epoch 61/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9651 - loss: 0.1010 - val_accuracy: 1.0000 - val_loss: 0.0272 - learning_rate: 0.0010\n","Epoch 62/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0539 - val_accuracy: 1.0000 - val_loss: 0.0321 - learning_rate: 0.0010\n","Epoch 63/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9827 - loss: 0.0503 - val_accuracy: 1.0000 - val_loss: 0.0389 - learning_rate: 0.0010\n","Epoch 64/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9860 - loss: 0.0494 - val_accuracy: 1.0000 - val_loss: 0.0392 - learning_rate: 0.0010\n","Epoch 65/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9696 - loss: 0.0855 - val_accuracy: 1.0000 - val_loss: 0.0390 - learning_rate: 0.0010\n","Epoch 66/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9477 - loss: 0.1433 - val_accuracy: 1.0000 - val_loss: 0.0270 - learning_rate: 0.0010\n","Epoch 67/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9940 - loss: 0.0492 - val_accuracy: 1.0000 - val_loss: 0.0196 - learning_rate: 0.0010\n","Epoch 68/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9523 - loss: 0.1342 - val_accuracy: 1.0000 - val_loss: 0.0190 - learning_rate: 0.0010\n","Epoch 69/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9535 - loss: 0.1158 - val_accuracy: 1.0000 - val_loss: 0.0287 - learning_rate: 0.0010\n","Epoch 70/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9734 - loss: 0.1152 - val_accuracy: 1.0000 - val_loss: 0.0251 - learning_rate: 0.0010\n","Epoch 71/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9733 - loss: 0.0775 - val_accuracy: 1.0000 - val_loss: 0.0168 - learning_rate: 0.0010\n","Epoch 72/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9482 - loss: 0.1053 - val_accuracy: 1.0000 - val_loss: 0.0165 - learning_rate: 0.0010\n","Epoch 73/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9736 - loss: 0.0885 - val_accuracy: 1.0000 - val_loss: 0.0190 - learning_rate: 0.0010\n","Epoch 74/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9656 - loss: 0.0960 - val_accuracy: 1.0000 - val_loss: 0.0256 - learning_rate: 0.0010\n","Epoch 75/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9842 - loss: 0.0553 - val_accuracy: 1.0000 - val_loss: 0.0249 - learning_rate: 0.0010\n","Epoch 76/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9781 - loss: 0.0767 - val_accuracy: 1.0000 - val_loss: 0.0216 - learning_rate: 0.0010\n","Epoch 77/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9544 - loss: 0.1422 - val_accuracy: 1.0000 - val_loss: 0.0192 - learning_rate: 0.0010\n","Epoch 78/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0466 - val_accuracy: 1.0000 - val_loss: 0.0212 - learning_rate: 0.0010\n","Epoch 79/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9742 - loss: 0.0664 - val_accuracy: 1.0000 - val_loss: 0.0181 - learning_rate: 0.0010\n","Epoch 80/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9651 - loss: 0.0935 - val_accuracy: 1.0000 - val_loss: 0.0135 - learning_rate: 0.0010\n","Epoch 81/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0584 - val_accuracy: 1.0000 - val_loss: 0.0142 - learning_rate: 0.0010\n","Epoch 82/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.0336 - val_accuracy: 1.0000 - val_loss: 0.0227 - learning_rate: 0.0010\n","Epoch 83/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9766 - loss: 0.0577 - val_accuracy: 1.0000 - val_loss: 0.0214 - learning_rate: 0.0010\n","Epoch 84/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0250 - val_accuracy: 1.0000 - val_loss: 0.0177 - learning_rate: 0.0010\n","Epoch 85/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0330 - val_accuracy: 1.0000 - val_loss: 0.0109 - learning_rate: 0.0010\n","Epoch 86/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9747 - loss: 0.0670 - val_accuracy: 1.0000 - val_loss: 0.0105 - learning_rate: 0.0010\n","Epoch 87/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9879 - loss: 0.0399 - val_accuracy: 1.0000 - val_loss: 0.0132 - learning_rate: 0.0010\n","Epoch 88/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9785 - loss: 0.0416 - val_accuracy: 1.0000 - val_loss: 0.0142 - learning_rate: 0.0010\n","Epoch 89/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9852 - loss: 0.0609 - val_accuracy: 1.0000 - val_loss: 0.0169 - learning_rate: 0.0010\n","Epoch 90/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9902 - loss: 0.0414 - val_accuracy: 1.0000 - val_loss: 0.0174 - learning_rate: 0.0010\n","Epoch 91/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9896 - loss: 0.0548 - val_accuracy: 1.0000 - val_loss: 0.0071 - learning_rate: 0.0010\n","Epoch 92/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9981 - loss: 0.0525 - val_accuracy: 1.0000 - val_loss: 0.0081 - learning_rate: 0.0010\n","Epoch 93/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9975 - loss: 0.0266 - val_accuracy: 1.0000 - val_loss: 0.0101 - learning_rate: 0.0010\n","Epoch 94/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 0.0499 - val_accuracy: 1.0000 - val_loss: 0.0119 - learning_rate: 0.0010\n","Epoch 95/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9675 - loss: 0.0807 - val_accuracy: 1.0000 - val_loss: 0.0125 - learning_rate: 0.0010\n","Epoch 96/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9928 - loss: 0.0550 - val_accuracy: 1.0000 - val_loss: 0.0116 - learning_rate: 0.0010\n","Epoch 97/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0278 - val_accuracy: 1.0000 - val_loss: 0.0109 - learning_rate: 0.0010\n","Epoch 98/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9714 - loss: 0.1096 - val_accuracy: 1.0000 - val_loss: 0.0079 - learning_rate: 0.0010\n","Epoch 99/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9881 - loss: 0.0417 - val_accuracy: 1.0000 - val_loss: 0.0079 - learning_rate: 0.0010\n","Epoch 100/100\n","\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0350 - val_accuracy: 1.0000 - val_loss: 0.0080 - learning_rate: 0.0010\n","Restoring model weights from the end of the best epoch: 91.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e054f20e8e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 83ms/step"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e054f20e8e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n","\n","--- Simplified Model Evaluation (2 Hidden Layers) ---\n","Test Accuracy: 1.0000\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           A       1.00      1.00      1.00        20\n","           D       1.00      1.00      1.00        20\n","           E       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        60\n","   macro avg       1.00      1.00      1.00        60\n","weighted avg       1.00      1.00      1.00        60\n","\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","# Perform Train/Test Split using the selected features\n","# X_selected and y come from the previous cells\n","X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42, stratify=y)\n","\n","print(f\"Training shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","# 1. Define the Simplified DNN architecture (2 hidden layers)\n","model_simple = Sequential([\n","    Input(shape=(X_train.shape[1],)),\n","\n","    # Hidden Layer 1\n","    Dense(64, activation='relu', kernel_initializer='he_normal'),\n","    BatchNormalization(),\n","    Dropout(0.3),\n","\n","    # Hidden Layer 2\n","    Dense(32, activation='relu', kernel_initializer='he_normal'),\n","    BatchNormalization(),\n","    Dropout(0.3),\n","\n","    # Output layer for 3 categories (A, D, E)\n","    Dense(3, activation='softmax')\n","])\n","\n","# 2. Compile the model\n","model_simple.compile(optimizer='adam',\n","                     loss='sparse_categorical_crossentropy',\n","                     metrics=['accuracy'])\n","\n","# 3. Define Callbacks\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001, verbose=1)\n","early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1)\n","\n","# 4. Train the model\n","history_simple = model_simple.fit(\n","    X_train, y_train,\n","    epochs=100,\n","    batch_size=16,\n","    validation_split=0.1,\n","    callbacks=[reduce_lr, early_stop],\n","    verbose=1\n",")\n","\n","# 5. Evaluate the model\n","loss, acc = model_simple.evaluate(X_test, y_test, verbose=0)\n","y_pred_prob = model_simple.predict(X_test)\n","y_pred = y_pred_prob.argmax(axis=1)\n","\n","print(\"\\n--- Simplified Model Evaluation (2 Hidden Layers) ---\")\n","print(f\"Test Accuracy: {acc:.4f}\")\n","\n","# Explicitly define target names based on the known classes ['A', 'D', 'E']\n","target_names = ['A', 'D', 'E']\n","\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred, target_names=target_names))"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e4fa3a45","executionInfo":{"status":"ok","timestamp":1763869922667,"user_tz":360,"elapsed":229,"user":{"displayName":"Ibrahim Al-Akash","userId":"03956035445069945231"}},"outputId":"47f3b609-8ce6-4d2a-b8c3-f8d209720df1"},"source":["import joblib\n","import os\n","\n","# Define the directory to save the model and artifacts\n","save_dir = '/content/drive/Shareddrives/AI Health Project/Project Code/Models'\n","os.makedirs(save_dir, exist_ok=True)\n","\n","# 1. Save the Model Parameters (Weights)\n","# Use .weights.h5 for Keras 3+ format compatibility\n","weights_path = os.path.join(save_dir, 'dnn_model_weights.weights.h5')\n","model_simple.save_weights(weights_path)\n","print(f\"Model weights saved to: {weights_path}\")\n","\n","# 2. Save the Full Model (Architecture + Weights + Optimizer state)\n","# This is recommended as it saves everything needed to resume or use the model\n","model_path = os.path.join(save_dir, 'dnn_model_full.keras')\n","model_simple.save(model_path)\n","print(f\"Full model saved to: {model_path}\")\n","\n","# 3. Save Preprocessing Objects (StandardScaler and LabelEncoder)\n","# These are CRITICAL for making predictions on new data later\n","joblib.dump(scaler, os.path.join(save_dir, 'scaler.pkl'))\n","joblib.dump(le, os.path.join(save_dir, 'label_encoder.pkl'))\n","print(\"Preprocessing objects (scaler, label_encoder) saved successfully.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model weights saved to: /content/drive/Shareddrives/AI Health Project/Project Code/Models/dnn_model_weights.weights.h5\n","Full model saved to: /content/drive/Shareddrives/AI Health Project/Project Code/Models/dnn_model_full.keras\n","Preprocessing objects (scaler, label_encoder) saved successfully.\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNHNOadsd9iV8Tp2zuUIhSE"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}